{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":121334,"databundleVersionId":14520005,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Assignment 4 (15 points) - Ioana-Delia Blendea","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport pickle\nimport os\nimport pandas as pd\nimport numpy as np\n\nclass ExtendedMNISTDataset(Dataset):\n    def __init__(self, root: str = \"/kaggle/input/fii-nn-2025-homework-4\", train: bool = True):\n        file = \"extended_mnist_test.pkl\"\n        if train:\n            file = \"extended_mnist_train.pkl\"\n        file = os.path.join(root, file)\n        \n        with open(file, \"rb\") as fp:\n            self.data = pickle.load(fp)\n\n    def __len__(self, ) -> int:\n        return len(self.data)\n\n    def __getitem__(self, i : int):\n        return self.data[i]\n\ntrain_data = []\ntrain_labels = []\nfor image, label in ExtendedMNISTDataset(train = True):\n    train_data.append(image.flatten())\n    train_labels.append(label)\n\ntest_data = []\nfor image, label in ExtendedMNISTDataset(train = False):\n    test_data.append(image.flatten())\n\nprint(\"all good :D\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-02T13:33:38.880589Z","iopub.execute_input":"2025-12-02T13:33:38.880843Z","iopub.status.idle":"2025-12-02T13:33:43.198280Z","shell.execute_reply.started":"2025-12-02T13:33:38.880822Z","shell.execute_reply":"2025-12-02T13:33:43.197529Z"}},"outputs":[{"name":"stdout","text":"all good :D\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.transforms import v2\nfrom sklearn.model_selection import train_test_split\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"motorul pytorch pornit pe: {device}\")\n\nX_all = np.array(train_data, dtype = np.float32) / 255.0\ny_all = np.array(train_labels, dtype = np.int64)\nX_sub = np.array(test_data, dtype = np.float32) / 255.0\n\nNUM_CLASSES = int(np.max(y_all)) + 1\n\nX_train, X_val, y_train, y_val = train_test_split(X_all, y_all, test_size = 0.1, random_state = 42)\n\nX_train_gpu = torch.tensor(X_train).to(device)\ny_train_gpu = torch.tensor(y_train).to(device)\nX_val_gpu = torch.tensor(X_val).to(device)\ny_val_gpu = torch.tensor(y_val).to(device)\nX_sub_gpu = torch.tensor(X_sub).to(device)\n\naugment_transform = v2.Compose([\n    v2.RandomRotation(degrees = 10),\n    v2.RandomAffine(degrees = 0, translate = (0.08, 0.08), scale = (0.95, 1.05)),\n])\n\ndef apply_augmentation(batch_images):\n    B = batch_images.shape[0]\n    img_reshaped = batch_images.view(B, 1, 28, 28)\n    img_aug = augment_transform(img_reshaped)\n    return img_aug.view(B, -1)\n\nclass TurboModel(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(784, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n\n            nn.Linear(1024, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x):\n        return self.layers(x)\n\nmodel = TurboModel(NUM_CLASSES).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T13:33:45.563988Z","iopub.execute_input":"2025-12-02T13:33:45.564407Z","iopub.status.idle":"2025-12-02T13:33:50.518391Z","shell.execute_reply.started":"2025-12-02T13:33:45.564362Z","shell.execute_reply":"2025-12-02T13:33:50.517595Z"}},"outputs":[{"name":"stdout","text":"motorul pytorch pornit pe: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"EPOCHS = 60\nBATCH_SIZE = 512\nnum_samples = X_train_gpu.shape[0]\nnum_batches = int(np.ceil(num_samples / BATCH_SIZE))\n\noptimizer = optim.AdamW(model.parameters(), lr = 0.001, weight_decay = 1e-4)\ncriterion = nn.CrossEntropyLoss()\nscheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr = 0.01, epochs = EPOCHS, steps_per_epoch = num_batches)\n\nfor epoch in range(EPOCHS):\n    model.train()\n    indices = torch.randperm(num_samples, device = device)\n    X_shuffled = X_train_gpu[indices]\n    y_shuffled = y_train_gpu[indices]\n    \n    for i in range(num_batches):\n        start_idx = i * BATCH_SIZE\n        end_idx = min(start_idx + BATCH_SIZE, num_samples)\n        \n        x_batch = X_shuffled[start_idx:end_idx]\n        y_batch = y_shuffled[start_idx:end_idx]\n\n        x_batch = apply_augmentation(x_batch)\n\n        optimizer.zero_grad()\n        outputs = model(x_batch)\n        loss = criterion(outputs, y_batch)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n    if (epoch + 1) % 5 == 0:\n        model.eval()\n        with torch.no_grad():\n            outputs = model(X_val_gpu)\n            _, predicted = torch.max(outputs, 1)\n            acc = (predicted == y_val_gpu).sum().item() / y_val_gpu.size(0)\n        print(f\"epoch {epoch+1} | acc: {acc*100:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T13:33:53.860881Z","iopub.execute_input":"2025-12-02T13:33:53.861565Z"}},"outputs":[{"name":"stdout","text":"epoch 5 | acc: 96.55\nepoch 10 | acc: 97.18\nepoch 15 | acc: 97.87\nepoch 20 | acc: 98.43\nepoch 25 | acc: 98.70\nepoch 30 | acc: 98.70\nepoch 35 | acc: 99.00\nepoch 40 | acc: 98.98\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"@torch.inference_mode()\ndef predict_with_tta(model, x_data, rounds = 10):\n    model.eval()\n    final_logits = model(x_data)\n\n    for i in range(rounds):\n        x_aug = apply_augmentation(x_data)\n        final_logits += model(x_aug)\n\n    return final_logits.argmax(dim=1).cpu().numpy()\n    \ntry:\n    predictions = predict_with_tta(model, X_sub_gpu, rounds = 10)\nexcept RuntimeError:\n    predictions = []\n    for i in range(0, len(X_sub_gpu), 5000):\n        batch = X_sub_gpu[i:i+5000]\n        predictions.extend(predict_with_tta(model, batch, rounds = 10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T02:49:40.277443Z","iopub.execute_input":"2025-12-02T02:49:40.278173Z","iopub.status.idle":"2025-12-02T02:49:40.366295Z","shell.execute_reply.started":"2025-12-02T02:49:40.278148Z","shell.execute_reply":"2025-12-02T02:49:40.365735Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions_csv = {\n    \"ID\": [],\n    \"target\": [],\n}\n\nfor i, label in enumerate(predictions):\n    predictions_csv[\"ID\"].append(i)\n    predictions_csv[\"target\"].append(label)\n\ndf = pd.DataFrame(predictions_csv)\ndf.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T02:49:44.270789Z","iopub.execute_input":"2025-12-02T02:49:44.271472Z","iopub.status.idle":"2025-12-02T02:49:44.311447Z","shell.execute_reply.started":"2025-12-02T02:49:44.271449Z","shell.execute_reply":"2025-12-02T02:49:44.310843Z"}},"outputs":[],"execution_count":null}]}